{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T19:08:30.004694Z",
     "start_time": "2025-09-09T19:08:28.511253Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as utils\n",
    "import pytorch_ssim\n",
    "import time \n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.nn.modules.loss import _Loss \n",
    "#from net.Ushape_Trans import *\n",
    "#from dataset import prepare_data, Dataset\n",
    "#from net.utils import *\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from utility import plots as plots, ptcolor as ptcolor, ptutils as ptutils, data as data\n",
    "from loss.LAB import *\n",
    "from loss.LCH import *\n",
    "from loss.VGG19_PercepLoss import *\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"  # 允许程序在存在重复的 OpenMP 库时继续运行\n",
    "\n",
    "# 设置 GPU 使用和默认 tensor 类型\n",
    "dtype = 'float32'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'  # 设置一个 环境变量，告诉程序只使用第 0 号 GPU\n",
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T19:08:39.919065Z",
     "start_time": "2025-09-09T19:08:39.868420Z"
    }
   },
   "outputs": [],
   "source": [
    "# split()：把一张图像缩放到不同分辨率（1/8, 1/4, 1/2, 原图），返回多尺度结果。\n",
    "# batch_PSNR()：批量计算 PSNR 评价指标。\n",
    "\n",
    "def split(img):\n",
    "    output=[]\n",
    "    output.append(F.interpolate(img, scale_factor=0.125))\n",
    "    output.append(F.interpolate(img, scale_factor=0.25))\n",
    "    output.append(F.interpolate(img, scale_factor=0.5))\n",
    "    output.append(img)\n",
    "    return output\n",
    "\n",
    "\n",
    "def batch_PSNR(img, imclean, data_range):\n",
    "    Img = img.data.cpu().numpy().astype(np.float32)\n",
    "    Iclean = imclean.data.cpu().numpy().astype(np.float32)\n",
    "    PSNR = 0\n",
    "    for i in range(Img.shape[0]):\n",
    "        PSNR += compare_psnr(Iclean[i,:,:,:], Img[i,:,:,:], data_range=data_range)\n",
    "    return (PSNR/Img.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T22:56:39.456156Z",
     "start_time": "2025-09-09T22:56:24.253029Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3449, 3, 256, 256])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从训练集目录里读取输入图像和 GT（目标图像），调整大小到 256×256，存入数组\n",
    "\n",
    "training_x=[]\n",
    "path= r'/root/LU2Net-master/LSUI/Train/train/'  #'./data/input/'#要改\n",
    "path_list = os.listdir(path)\n",
    "path_list.sort(key=lambda x:int(x.split('.')[0]))\n",
    "for item in path_list:\n",
    "    impath=path+item\n",
    "    #print(\"开始处理\"+impath)\n",
    "    imgx= cv2.imread(path+item)\n",
    "    imgx = cv2.cvtColor(imgx, cv2.COLOR_BGR2RGB)\n",
    "    imgx=cv2.resize(imgx,(256,256))\n",
    "    training_x.append(imgx)   \n",
    "\n",
    "X_train = []\n",
    "\n",
    "for features in training_x:\n",
    "    X_train.append(features)\n",
    "    \n",
    "X_train = np.array(X_train)\n",
    "\n",
    "X_train=X_train.astype(dtype)\n",
    "X_train= torch.from_numpy(X_train)\n",
    "X_train=X_train.permute(0,3,1,2)\n",
    "\n",
    "X_train=X_train/255.0\n",
    "X_train.shape\n",
    "\n",
    "############################################################\n",
    "############################################################\n",
    "\n",
    "training_y=[]\n",
    "path= r'/root/LU2Net-master/LSUI/Train/GT/'     #'./data/GT/'#要改\n",
    "path_list = os.listdir(path)\n",
    "path_list.sort(key=lambda x:int(x.split('.')[0]))\n",
    "for item in path_list:\n",
    "    impath=path+item\n",
    "    #print(\"开始处理\"+impath)\n",
    "    imgx= cv2.imread(path+item)\n",
    "    imgx = cv2.cvtColor(imgx, cv2.COLOR_BGR2RGB)\n",
    "    imgx=cv2.resize(imgx,(256,256))\n",
    "    training_y.append(imgx)\n",
    "\n",
    "y_train = []\n",
    "\n",
    "for features in training_y:\n",
    "    y_train.append(features)\n",
    "    \n",
    "y_train = np.array(y_train)\n",
    "\n",
    "y_train=y_train.astype(dtype)\n",
    "y_train= torch.from_numpy(y_train)\n",
    "y_train=y_train.permute(0,3,1,2)\n",
    "\n",
    "y_train=y_train/255.0\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T22:58:00.498048Z",
     "start_time": "2025-09-09T22:57:53.038218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([830, 3, 256, 256])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取测试集（输入图像和 GT），同样 resize 到 256×256\n",
    "\n",
    "test_x=[]\n",
    "path= r'/root/LU2Net-master/LSUI/Test/test/'       #'./test/input/'#要改\n",
    "path_list = os.listdir(path)\n",
    "# 只保留文件名是“数字.后缀”格式的 #####增加的\n",
    "path_list = [f for f in path_list if f.split('.')[0].isdigit()]\n",
    "path_list.sort(key=lambda x:int(x.split('.')[0]))\n",
    "for item in path_list:\n",
    "    impath=path+item\n",
    "    #print(\"开始处理\"+impath)\n",
    "    imgx= cv2.imread(path+item)\n",
    "    imgx = cv2.cvtColor(imgx, cv2.COLOR_BGR2RGB)\n",
    "    imgx=cv2.resize(imgx,(256,256))\n",
    "    test_x.append(imgx)\n",
    "    \n",
    "x_test = []\n",
    "\n",
    "for features in test_x:\n",
    "    x_test.append(features)\n",
    "    \n",
    "x_test = np.array(x_test)\n",
    "\n",
    "x_test=x_test.astype(dtype)\n",
    "x_test= torch.from_numpy(x_test)\n",
    "x_test=x_test.permute(0,3,1,2)\n",
    "\n",
    "x_test=x_test/255.0\n",
    "x_test.shape\n",
    "\n",
    "############################################################\n",
    "############################################################\n",
    "\n",
    "test_Y=[]\n",
    "path= r'/root/LU2Net-master/LSUI/Test/GT/'   #'./test/GT/'#要改\n",
    "path_list = os.listdir(path)\n",
    "# 只保留文件名是“数字.后缀”格式的 #####增加的\n",
    "path_list = [f for f in path_list if f.split('.')[0].isdigit()]\n",
    "path_list.sort(key=lambda x:int(x.split('.')[0]))\n",
    "for item in path_list:\n",
    "    impath=path+item\n",
    "    #print(\"开始处理\"+impath)\n",
    "    imgx= cv2.imread(path+item)\n",
    "    imgx = cv2.cvtColor(imgx, cv2.COLOR_BGR2RGB)\n",
    "    imgx=cv2.resize(imgx,(256,256))\n",
    "    test_Y.append(imgx)\n",
    "    \n",
    "Y_test = []\n",
    "\n",
    "for features in test_Y:\n",
    "    Y_test.append(features)\n",
    "    \n",
    "Y_test = np.array(Y_test)\n",
    "#X_train = np.array(X_train)\n",
    "\n",
    "Y_test=Y_test.astype(dtype)\n",
    "Y_test= torch.from_numpy(Y_test)\n",
    "Y_test=Y_test.permute(0,3,1,2)\n",
    "\n",
    "Y_test=Y_test/255.0\n",
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T22:58:14.434121Z",
     "start_time": "2025-09-09T22:58:14.355069Z"
    }
   },
   "outputs": [],
   "source": [
    "# 构造 PyTorch Dataset 和 DataLoader 用于训练\n",
    "# 定义各种损失函数（GAN、像素、SSIM、VGG感知、Lab颜色空间损失）\n",
    "\n",
    "import torch.utils.data as dataf\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "dataset = dataf.TensorDataset(X_train,y_train)\n",
    "loader = dataf.DataLoader(dataset, batch_size=1, shuffle=True,num_workers=4)\n",
    "\n",
    "# 定义损失函数\n",
    "criterion_GAN      = nn.MSELoss(reduction='mean').cuda()\n",
    "criterion_pixelwise= nn.MSELoss(reduction='mean').cuda()\n",
    "MSE                = nn.MSELoss(reduction='mean').cuda()\n",
    "SSIM               = pytorch_ssim.SSIM().cuda()\n",
    "L_vgg              = VGG19_PercepLoss().cuda()\n",
    "L_lab              = lab_Loss().cuda()\n",
    "L_lch              = lch_Loss().cuda()\n",
    "\n",
    "# Loss weight of L1 pixel-wise loss between translated image and real image\n",
    "lambda_pixel=0.1\n",
    "lambda_lab=0.001\n",
    "lambda_lch=1\n",
    "lambda_con = 100\n",
    "lambda_ssim=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修改后"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化主模型 LightUNet；是否加载预训练模型\n",
    "\n",
    "import HDAMS_Net\n",
    "LightUNet = HDAMS_Net.HDAMS_Net().cuda()\n",
    "\n",
    "# 如果有保存的模型，则加载模型，并在其基础上继续训练\n",
    "# use_pretrain=True\n",
    "use_pretrain=False\n",
    "if use_pretrain:\n",
    "    \n",
    "    # start_epoch=490\n",
    "    start_epoch=0\n",
    "    LightUNet.load_state_dict(torch.load(\"/root/LU2Net-master/LightUNet_%d.pth\" % (start_epoch)))\n",
    "    print('successfully loading epoch {} 成功！'.format(start_epoch))\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    print('No pretrain model found, training will start from scratch!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T23:02:04.850964Z",
     "start_time": "2025-09-09T23:02:04.748753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pretrain model found, training will start from scratch!\n"
     ]
    }
   ],
   "source": [
    "# 初始化主模型 LightUNet；是否加载预训练模型\n",
    "\n",
    "import LU2Net\n",
    "LightUNet = LU2Net.LU2Net().cuda()\n",
    "\n",
    "# 如果有保存的模型，则加载模型，并在其基础上继续训练\n",
    "# use_pretrain=True\n",
    "use_pretrain=False\n",
    "if use_pretrain:\n",
    "    \n",
    "    # start_epoch=490\n",
    "    start_epoch=0\n",
    "    LightUNet.load_state_dict(torch.load(\"/root/LU2Net-master/LightUNet_%d.pth\" % (start_epoch)))\n",
    "    print('successfully loading epoch {} 成功！'.format(start_epoch))\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    print('No pretrain model found, training will start from scratch!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T23:02:33.864912Z",
     "start_time": "2025-09-09T23:02:33.825182Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义函数 sample_images()，从测试集中随机取一张图片，生成预测结果并保存对比\n",
    "\n",
    "def sample_images(batches_done):\n",
    "    \"\"\"Saves a generated sample from the validation set\"\"\"\n",
    "    LightUNet.eval()\n",
    "    i=random.randrange(1,90)\n",
    "    real_A = Variable(x_test[i,:,:,:]).cuda()\n",
    "    real_B = Variable(Y_test[i,:,:,:]).cuda()\n",
    "    real_A=real_A.unsqueeze(0)\n",
    "    real_B=real_B.unsqueeze(0)\n",
    "    fake_B = LightUNet(real_A)\n",
    "    #print(fake_B.shape)\n",
    "    imgx=fake_B.data\n",
    "    imgy=real_B.data\n",
    "    x=imgx[:,:,:,:]\n",
    "    y=imgy[:,:,:,:]\n",
    "    img_sample = torch.cat((x,y), -2)\n",
    "    save_image(img_sample, \"images/%s/%s.png\" % ('results', batches_done), nrow=5, normalize=True)#要改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T23:02:38.040140Z",
     "start_time": "2025-09-09T23:02:37.991383Z"
    }
   },
   "outputs": [],
   "source": [
    "# 设置优化器 Adam，学习率调度器，CUDA 配置\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "LR=0.0005\n",
    "\n",
    "# Optimizers\n",
    "optimizer = torch.optim.Adam(LightUNet.parameters(), lr=LR,  betas=(0.5, 0.999))\n",
    "scheduler=lr_scheduler.StepLR(optimizer,step_size=40,gamma=0.8)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0\n",
      "[Epoch 0/1500] [Batch 3448/3449][PSNR: 21.729459] [SSIM: 0.832180] [loss: 295.494995] ,[lab: 339.099625],[lch: 1.293802], [pixel: 0.000672],[VGG_loss: 26.674655]epoch1\n",
      "epoch2\n",
      "epoch3\n",
      "epoch4\n",
      "epoch5\n",
      "epoch6\n",
      "epoch7\n",
      "epoch8\n",
      "epoch9\n",
      "epoch10\n",
      "[Epoch 10/1500] [Batch 3448/3449][PSNR: 23.462398] [SSIM: 0.844405] [loss: 70.317596] ,[lab: 133.586578],[lch: 1.046382], [pixel: 0.000451],[VGG_loss: 10.707246]epoch11\n",
      "epoch12\n",
      "epoch13\n",
      "epoch14\n",
      "epoch15\n",
      "epoch16\n",
      "epoch17\n",
      "epoch18\n",
      "epoch19\n",
      "epoch20\n",
      "[Epoch 20/1500] [Batch 3448/3449][PSNR: 25.765349] [SSIM: 0.952382] [loss: 26.474304] ,[lab: 108.005469],[lch: 0.817065], [pixel: 0.000267],[VGG_loss: 5.536105]epoch21\n",
      "epoch22\n",
      "epoch23\n",
      "epoch24\n",
      "epoch25\n",
      "epoch26\n",
      "epoch27\n",
      "epoch28\n",
      "epoch29\n",
      "epoch30\n",
      "[Epoch 30/1500] [Batch 3448/3449][PSNR: 26.804490] [SSIM: 0.902323] [loss: -5.003420] ,[lab: 68.095297],[lch: 0.591323], [pixel: 0.000209],[VGG_loss: 11.220148]epoch31\n",
      "epoch32\n",
      "epoch33\n",
      "epoch34\n",
      "epoch35\n",
      "epoch36\n",
      "epoch37\n",
      "epoch38\n",
      "epoch39\n",
      "epoch40\n",
      "[Epoch 40/1500] [Batch 3448/3449][PSNR: 26.521448] [SSIM: 0.899229] [loss: 22.541973] ,[lab: 93.043672],[lch: 0.598713], [pixel: 0.000223],[VGG_loss: 13.433811]epoch41\n",
      "epoch42\n",
      "epoch43\n",
      "epoch44\n",
      "epoch45\n",
      "epoch46\n",
      "epoch47\n",
      "epoch48\n",
      "epoch49\n",
      "epoch50\n",
      "[Epoch 50/1500] [Batch 3448/3449][PSNR: 26.252880] [SSIM: 0.903660] [loss: 42.626167] ,[lab: 119.318797],[lch: 0.732709], [pixel: 0.000237],[VGG_loss: 6.346038]epoch51\n",
      "epoch52\n",
      "epoch53\n",
      "epoch54\n",
      "epoch55\n",
      "epoch56\n",
      "epoch57\n",
      "epoch58\n",
      "epoch59\n",
      "epoch60\n",
      "[Epoch 60/1500] [Batch 3448/3449][PSNR: 26.640131] [SSIM: 0.822858] [loss: 59.993240] ,[lab: 124.676602],[lch: 0.525931], [pixel: 0.000217],[VGG_loss: 12.342948]epoch61\n",
      "epoch62\n",
      "epoch63\n",
      "epoch64\n",
      "epoch65\n",
      "epoch66\n",
      "epoch67\n",
      "epoch68\n",
      "epoch69\n",
      "epoch70\n",
      "[Epoch 70/1500] [Batch 3448/3449][PSNR: 26.196837] [SSIM: 0.868888] [loss: 73.012581] ,[lab: 137.359547],[lch: 0.683669], [pixel: 0.000240],[VGG_loss: 15.704885]epoch71\n",
      "epoch72\n",
      "epoch73\n",
      "epoch74\n",
      "epoch75\n",
      "epoch76\n",
      "epoch77\n",
      "epoch78\n",
      "epoch79\n",
      "epoch80\n",
      "[Epoch 80/1500] [Batch 3448/3449][PSNR: 22.541134] [SSIM: 0.921018] [loss: -57.626282] ,[lab: 22.045469],[lch: 1.031309], [pixel: 0.000560],[VGG_loss: 2.116353]epoch81\n",
      "epoch82\n",
      "epoch83\n",
      "epoch84\n",
      "epoch85\n",
      "epoch86\n",
      "epoch87\n",
      "epoch88\n",
      "epoch89\n",
      "epoch90\n",
      "[Epoch 90/1500] [Batch 3448/3449][PSNR: 27.605521] [SSIM: 0.902901] [loss: -43.847496] ,[lab: 36.162855],[lch: 0.536997], [pixel: 0.000174],[VGG_loss: 4.909559]epoch91\n",
      "epoch92\n",
      "epoch93\n",
      "epoch94\n",
      "epoch95\n",
      "epoch96\n",
      "epoch97\n",
      "epoch98\n",
      "epoch99\n",
      "epoch100\n",
      "[Epoch 100/1500] [Batch 3448/3449][PSNR: 30.175518] [SSIM: 0.900239] [loss: 30.257774] ,[lab: 103.554078],[lch: 0.503655], [pixel: 0.000097],[VGG_loss: 11.690904]epoch101\n",
      "epoch102\n",
      "epoch103\n",
      "epoch104\n",
      "epoch105\n",
      "epoch106\n",
      "epoch107\n",
      "epoch108\n",
      "epoch109\n",
      "epoch110\n",
      "[Epoch 110/1500] [Batch 3448/3449][PSNR: 30.701631] [SSIM: 0.940644] [loss: -2.694758] ,[lab: 80.142625],[lch: 0.473388], [pixel: 0.000085],[VGG_loss: 6.493010]epoch111\n",
      "epoch112\n",
      "epoch113\n",
      "epoch114\n",
      "epoch115\n",
      "epoch116\n",
      "epoch117\n",
      "epoch118\n",
      "epoch119\n",
      "epoch120\n",
      "[Epoch 120/1500] [Batch 3448/3449][PSNR: 26.736338] [SSIM: 0.848869] [loss: 44.879719] ,[lab: 96.681641],[lch: 0.573430], [pixel: 0.000213],[VGG_loss: 27.350453]epoch121\n",
      "epoch122\n",
      "epoch123\n",
      "epoch124\n",
      "epoch125\n",
      "epoch126\n",
      "epoch127\n",
      "epoch128\n",
      "epoch129\n",
      "epoch130\n",
      "[Epoch 130/1500] [Batch 3448/3449][PSNR: 27.606146] [SSIM: 0.957917] [loss: -40.067734] ,[lab: 47.226328],[lch: 0.741031], [pixel: 0.000174],[VGG_loss: 1.087169]epoch131\n",
      "epoch132\n",
      "epoch133\n",
      "epoch134\n",
      "epoch135\n",
      "epoch136\n",
      "epoch137\n",
      "epoch138\n",
      "epoch139\n",
      "epoch140\n",
      "[Epoch 140/1500] [Batch 3448/3449][PSNR: 30.003579] [SSIM: 0.911237] [loss: -43.092278] ,[lab: 39.670156],[lch: 0.522663], [pixel: 0.000100],[VGG_loss: 3.134556]epoch141\n",
      "epoch142\n",
      "epoch143\n",
      "epoch144\n",
      "epoch145\n",
      "epoch146\n",
      "epoch147\n",
      "epoch148\n",
      "epoch149\n",
      "epoch150\n",
      "[Epoch 150/1500] [Batch 3448/3449][PSNR: 31.501045] [SSIM: 0.972836] [loss: 6.651727] ,[lab: 98.063711],[lch: 0.416533], [pixel: 0.000073],[VGG_loss: 1.706223]epoch151\n",
      "epoch152\n",
      "epoch153\n",
      "epoch154\n",
      "epoch155\n",
      "epoch156\n",
      "epoch157\n",
      "epoch158\n",
      "epoch159\n",
      "epoch160\n",
      "[Epoch 160/1500] [Batch 3448/3449][PSNR: 34.560850] [SSIM: 0.981884] [loss: -59.466534] ,[lab: 34.436504],[lch: 0.304445], [pixel: 0.000035],[VGG_loss: 1.240831]epoch161\n",
      "epoch162\n",
      "epoch163\n",
      "epoch164\n",
      "epoch165\n",
      "epoch166\n",
      "epoch167\n",
      "epoch168\n",
      "epoch169\n",
      "epoch170\n",
      "[Epoch 170/1500] [Batch 3448/3449][PSNR: 22.436488] [SSIM: 0.945613] [loss: -34.043621] ,[lab: 47.065078],[lch: 0.879981], [pixel: 0.000571],[VGG_loss: 4.652184]epoch171\n",
      "epoch172\n",
      "epoch173\n",
      "epoch174\n",
      "epoch175\n",
      "epoch176\n",
      "epoch177\n",
      "epoch178\n",
      "epoch179\n",
      "epoch180\n",
      "[Epoch 180/1500] [Batch 3448/3449][PSNR: 29.242634] [SSIM: 0.876630] [loss: -32.841827] ,[lab: 40.413363],[lch: 0.444503], [pixel: 0.000119],[VGG_loss: 9.962673]epoch181\n",
      "epoch182\n",
      "epoch183\n",
      "epoch184\n",
      "epoch185\n",
      "epoch186\n",
      "epoch187\n",
      "epoch188\n",
      "epoch189\n",
      "epoch190\n",
      "[Epoch 190/1500] [Batch 3448/3449][PSNR: 33.611055] [SSIM: 0.946904] [loss: -44.421562] ,[lab: 41.546121],[lch: 0.360910], [pixel: 0.000044],[VGG_loss: 5.113557]epoch191\n",
      "epoch192\n",
      "epoch193\n",
      "epoch194\n",
      "epoch195\n",
      "epoch196\n",
      "epoch197\n",
      "epoch198\n",
      "epoch199\n",
      "epoch200\n",
      "[Epoch 200/1500] [Batch 3448/3449][PSNR: 27.492566] [SSIM: 0.913423] [loss: -40.021454] ,[lab: 39.150813],[lch: 0.577522], [pixel: 0.000178],[VGG_loss: 6.394674]epoch201\n",
      "epoch202\n",
      "epoch203\n",
      "epoch204\n",
      "epoch205\n",
      "epoch206\n",
      "epoch207\n",
      "epoch208\n",
      "epoch209\n",
      "epoch210\n",
      "[Epoch 210/1500] [Batch 3448/3449][PSNR: 33.827759] [SSIM: 0.982040] [loss: -58.451714] ,[lab: 33.823855],[lch: 0.316067], [pixel: 0.000042],[VGG_loss: 2.767717]epoch211\n",
      "epoch212\n",
      "epoch213\n",
      "epoch214\n",
      "epoch215\n",
      "epoch216\n",
      "epoch217\n",
      "epoch218\n",
      "epoch219\n",
      "epoch220\n",
      "[Epoch 220/1500] [Batch 3448/3449][PSNR: 28.752586] [SSIM: 0.897869] [loss: -37.417057] ,[lab: 40.488172],[lch: 0.500880], [pixel: 0.000133],[VGG_loss: 6.872772]epoch221\n",
      "epoch222\n",
      "epoch223\n",
      "epoch224\n",
      "epoch225\n",
      "epoch226\n",
      "epoch227\n",
      "epoch228\n",
      "epoch229\n",
      "epoch230\n",
      "[Epoch 230/1500] [Batch 3448/3449][PSNR: 28.956204] [SSIM: 0.916378] [loss: -1.244162] ,[lab: 82.005148],[lch: 0.461545], [pixel: 0.000127],[VGG_loss: 3.772961]epoch231\n",
      "epoch232\n",
      "epoch233\n",
      "epoch234\n",
      "epoch235\n",
      "epoch236\n",
      "epoch237\n",
      "epoch238\n",
      "epoch239\n",
      "epoch240\n",
      "[Epoch 240/1500] [Batch 3448/3449][PSNR: 31.917802] [SSIM: 0.939868] [loss: -22.106392] ,[lab: 59.336418],[lch: 0.353380], [pixel: 0.000064],[VGG_loss: 9.010138]epoch241\n",
      "epoch242\n",
      "epoch243\n",
      "epoch244\n",
      "epoch245\n",
      "epoch246\n",
      "epoch247\n",
      "epoch248\n",
      "epoch249\n",
      "epoch250\n",
      "[Epoch 250/1500] [Batch 3448/3449][PSNR: 28.173645] [SSIM: 0.968453] [loss: 2.177463] ,[lab: 89.710023],[lch: 0.586342], [pixel: 0.000156],[VGG_loss: 3.449145]epoch251\n",
      "epoch252\n",
      "epoch253\n",
      "epoch254\n",
      "epoch255\n",
      "epoch256\n",
      "epoch257\n",
      "epoch258\n",
      "epoch259\n",
      "epoch260\n",
      "[Epoch 260/1500] [Batch 3448/3449][PSNR: 29.626561] [SSIM: 0.818375] [loss: -29.514698] ,[lab: 37.513492],[lch: 0.335943], [pixel: 0.000109],[VGG_loss: 11.449749]epoch261\n",
      "epoch262\n",
      "epoch263\n",
      "epoch264\n",
      "epoch265\n",
      "epoch266\n",
      "epoch267\n",
      "epoch268\n",
      "epoch269\n",
      "epoch270\n",
      "[Epoch 270/1500] [Batch 3448/3449][PSNR: 34.712408] [SSIM: 0.977447] [loss: -71.573502] ,[lab: 21.595604],[lch: 0.307203], [pixel: 0.000056],[VGG_loss: 1.503511]epoch271\n",
      "epoch272\n",
      "epoch273\n",
      "epoch274\n",
      "epoch275\n",
      "epoch276\n",
      "epoch277\n",
      "epoch278\n",
      "epoch279\n",
      "epoch280\n",
      "[Epoch 280/1500] [Batch 3448/3449][PSNR: 26.689897] [SSIM: 0.862909] [loss: 8.341452] ,[lab: 75.779828],[lch: 0.580096], [pixel: 0.000215],[VGG_loss: 13.051341]epoch281\n",
      "epoch282\n",
      "epoch283\n",
      "epoch284\n",
      "epoch285\n",
      "epoch286\n",
      "epoch287\n",
      "epoch288\n",
      "epoch289\n",
      "epoch290\n",
      "[Epoch 290/1500] [Batch 3448/3449][PSNR: 26.951570] [SSIM: 0.801949] [loss: 46.932129] ,[lab: 109.309352],[lch: 0.575721], [pixel: 0.000203],[VGG_loss: 12.060279]epoch291\n",
      "epoch292\n",
      "epoch293\n",
      "epoch294\n",
      "epoch295\n",
      "epoch296\n",
      "epoch297\n",
      "epoch298\n",
      "epoch299\n",
      "epoch300\n",
      "[Epoch 300/1500] [Batch 3448/3449][PSNR: 29.864768] [SSIM: 0.923830] [loss: -23.025944] ,[lab: 58.652957],[lch: 0.404650], [pixel: 0.000103],[VGG_loss: 6.657475]epoch301\n",
      "epoch302\n",
      "epoch303\n",
      "epoch304\n",
      "epoch305\n",
      "epoch306\n",
      "epoch307\n",
      "epoch308\n",
      "epoch309\n",
      "epoch310\n",
      "[Epoch 310/1500] [Batch 3448/3449][PSNR: 32.379822] [SSIM: 0.970819] [loss: -71.554062] ,[lab: 20.554574],[lch: 0.327181], [pixel: 0.000060],[VGG_loss: 1.701422]epoch311\n",
      "epoch312\n",
      "epoch313\n",
      "epoch314\n",
      "epoch315\n",
      "epoch316\n",
      "epoch317\n",
      "epoch318\n",
      "epoch319\n",
      "epoch320\n",
      "[Epoch 320/1500] [Batch 3448/3449][PSNR: 27.675340] [SSIM: 0.888761] [loss: 56.883183] ,[lab: 123.768836],[lch: 0.729116], [pixel: 0.000171],[VGG_loss: 14.699137]epoch321\n",
      "epoch322\n",
      "epoch323\n",
      "epoch324\n",
      "epoch325\n",
      "epoch326\n",
      "epoch327\n",
      "epoch328\n",
      "epoch329\n",
      "epoch330\n",
      "[Epoch 330/1500] [Batch 3448/3449][PSNR: 29.478983] [SSIM: 0.868998] [loss: -4.869651] ,[lab: 58.804875],[lch: 0.436820], [pixel: 0.000113],[VGG_loss: 18.857014]epoch331\n",
      "epoch332\n",
      "epoch333\n",
      "epoch334\n",
      "epoch335\n",
      "epoch336\n",
      "epoch337\n",
      "epoch338\n",
      "epoch339\n",
      "epoch340\n",
      "[Epoch 340/1500] [Batch 3448/3449][PSNR: 28.958041] [SSIM: 0.868119] [loss: -20.341949] ,[lab: 52.078273],[lch: 0.476865], [pixel: 0.000127],[VGG_loss: 9.622867]epoch341\n",
      "epoch342\n",
      "epoch343\n",
      "epoch344\n",
      "epoch345\n",
      "epoch346\n",
      "epoch347\n",
      "epoch348\n",
      "epoch349\n",
      "epoch350\n",
      "[Epoch 350/1500] [Batch 3448/3449][PSNR: 29.672429] [SSIM: 0.927562] [loss: 0.417585] ,[lab: 81.010406],[lch: 0.520531], [pixel: 0.000108],[VGG_loss: 6.957994]epoch351\n",
      "epoch352\n",
      "epoch353\n",
      "epoch354\n",
      "epoch355\n",
      "epoch356\n",
      "epoch357\n",
      "epoch358\n",
      "epoch359\n",
      "epoch360\n",
      "[Epoch 360/1500] [Batch 3448/3449][PSNR: 26.247764] [SSIM: 0.866666] [loss: 4.593822] ,[lab: 69.592305],[lch: 0.576911], [pixel: 0.000237],[VGG_loss: 15.898752]epoch361\n",
      "epoch362\n",
      "epoch363\n",
      "epoch364\n",
      "epoch365\n",
      "epoch366\n",
      "epoch367\n",
      "epoch368\n",
      "epoch369\n",
      "epoch370\n",
      "[Epoch 370/1500] [Batch 3448/3449][PSNR: 28.477345] [SSIM: 0.970482] [loss: -11.718512] ,[lab: 78.768898],[lch: 0.563001], [pixel: 0.000142],[VGG_loss: 0.930671]epoch371\n",
      "epoch372\n",
      "epoch373\n",
      "epoch374\n",
      "epoch375\n",
      "epoch376\n",
      "epoch377\n",
      "epoch378\n",
      "epoch379\n",
      "epoch380\n",
      "[Epoch 380/1500] [Batch 3448/3449][PSNR: 30.034633] [SSIM: 0.928651] [loss: -37.774662] ,[lab: 41.411219],[lch: 0.464335], [pixel: 0.000099],[VGG_loss: 9.035777]epoch381\n",
      "epoch382\n",
      "epoch383\n",
      "epoch384\n",
      "epoch385\n",
      "epoch386\n",
      "epoch387\n",
      "epoch388\n",
      "epoch389\n",
      "epoch390\n",
      "[Epoch 390/1500] [Batch 3448/3449][PSNR: 25.620772] [SSIM: 0.918787] [loss: -46.744446] ,[lab: 33.879219],[lch: 0.700870], [pixel: 0.000274],[VGG_loss: 4.246050]epoch391\n",
      "epoch392\n",
      "epoch393\n",
      "epoch394\n",
      "epoch395\n",
      "epoch396\n",
      "epoch397\n",
      "epoch398\n",
      "epoch399\n",
      "epoch400\n",
      "[Epoch 400/1500] [Batch 3448/3449][PSNR: 33.331186] [SSIM: 0.963879] [loss: -15.921532] ,[lab: 72.157836],[lch: 0.368590], [pixel: 0.000047],[VGG_loss: 4.622566]epoch401\n",
      "epoch402\n",
      "epoch403\n",
      "epoch404\n",
      "epoch405\n",
      "epoch406\n",
      "epoch407\n",
      "epoch408\n",
      "epoch409\n",
      "epoch410\n",
      "[Epoch 410/1500] [Batch 3448/3449][PSNR: 18.457696] [SSIM: 0.848587] [loss: 201.422470] ,[lab: 238.906625],[lch: 1.739623], [pixel: 0.001794],[VGG_loss: 29.976547]epoch411\n",
      "epoch412\n",
      "epoch413\n",
      "epoch414\n",
      "epoch415\n",
      "epoch416\n",
      "epoch417\n",
      "epoch418\n",
      "epoch419\n",
      "epoch420\n",
      "[Epoch 420/1500] [Batch 3448/3449][PSNR: 27.361214] [SSIM: 0.874998] [loss: 6.561554] ,[lab: 79.078563],[lch: 0.548839], [pixel: 0.000184],[VGG_loss: 9.494182]epoch421\n",
      "epoch422\n",
      "epoch423\n",
      "epoch424\n",
      "epoch425\n",
      "epoch426\n",
      "epoch427\n",
      "epoch428\n",
      "epoch429\n",
      "epoch430\n",
      "[Epoch 430/1500] [Batch 3448/3449][PSNR: 29.305653] [SSIM: 0.893384] [loss: 4.948287] ,[lab: 82.730695],[lch: 0.450703], [pixel: 0.000122],[VGG_loss: 7.048826]epoch431\n",
      "epoch432\n",
      "epoch433\n",
      "epoch434\n",
      "epoch435\n",
      "epoch436\n",
      "epoch437\n",
      "epoch438\n",
      "epoch439\n",
      "epoch440\n",
      "[Epoch 440/1500] [Batch 3448/3449][PSNR: 27.866426] [SSIM: 0.870807] [loss: -2.194858] ,[lab: 68.507594],[lch: 0.503578], [pixel: 0.000163],[VGG_loss: 11.342327]epoch441\n",
      "epoch442\n",
      "epoch443\n",
      "epoch444\n",
      "epoch445\n",
      "epoch446\n",
      "epoch447\n",
      "epoch448\n",
      "epoch449\n",
      "epoch450\n",
      "[Epoch 450/1500] [Batch 3448/3449][PSNR: 29.390380] [SSIM: 0.892969] [loss: 1.011957] ,[lab: 72.603328],[lch: 0.438448], [pixel: 0.000115],[VGG_loss: 13.320921]epoch451\n",
      "epoch452\n",
      "epoch453\n",
      "epoch454\n",
      "epoch455\n",
      "epoch456\n",
      "epoch457\n",
      "epoch458\n",
      "epoch459\n",
      "epoch460\n",
      "[Epoch 460/1500] [Batch 3448/3449][PSNR: 30.268705] [SSIM: 0.887657] [loss: -9.150681] ,[lab: 60.520496],[lch: 0.490221], [pixel: 0.000094],[VGG_loss: 14.192170]epoch461\n",
      "epoch462\n",
      "epoch463\n",
      "epoch464\n",
      "epoch465\n",
      "epoch466\n",
      "epoch467\n",
      "epoch468\n",
      "epoch469\n",
      "epoch470\n",
      "[Epoch 470/1500] [Batch 3448/3449][PSNR: 27.384239] [SSIM: 0.946486] [loss: -45.193359] ,[lab: 38.170527],[lch: 0.653852], [pixel: 0.000183],[VGG_loss: 4.746015]epoch471\n",
      "epoch472\n",
      "epoch473\n",
      "epoch474\n",
      "epoch475\n",
      "epoch476\n",
      "epoch477\n",
      "epoch478\n",
      "epoch479\n",
      "epoch480\n",
      "[Epoch 480/1500] [Batch 3448/3449][PSNR: 29.386019] [SSIM: 0.911230] [loss: -39.883213] ,[lab: 39.465766],[lch: 0.490263], [pixel: 0.000116],[VGG_loss: 6.871298]epoch481\n",
      "epoch482\n",
      "epoch483\n",
      "epoch484\n",
      "epoch485\n",
      "epoch486\n",
      "epoch487\n",
      "epoch488\n",
      "epoch489\n",
      "epoch490\n",
      "[Epoch 490/1500] [Batch 3448/3449][PSNR: 31.282602] [SSIM: 0.916997] [loss: -21.417286] ,[lab: 55.996828],[lch: 0.390282], [pixel: 0.000074],[VGG_loss: 10.382707]epoch491\n",
      "epoch492\n",
      "epoch493\n",
      "epoch494\n",
      "epoch495\n",
      "epoch496\n",
      "epoch497\n",
      "epoch498\n",
      "epoch499\n",
      "epoch500\n",
      "[Epoch 500/1500] [Batch 3448/3449][PSNR: 25.790272] [SSIM: 0.892092] [loss: -4.961111] ,[lab: 70.098016],[lch: 0.694576], [pixel: 0.000264],[VGG_loss: 7.204056]epoch501\n",
      "epoch502\n",
      "epoch503\n",
      "epoch504\n",
      "epoch505\n",
      "epoch506\n",
      "epoch507\n",
      "epoch508\n",
      "epoch509\n",
      "epoch510\n",
      "[Epoch 510/1500] [Batch 3448/3449][PSNR: 23.847580] [SSIM: 0.966147] [loss: -72.250847] ,[lab: 14.363764],[lch: 0.866141], [pixel: 0.000445],[VGG_loss: 1.338280]epoch511\n",
      "epoch512\n",
      "epoch513\n",
      "epoch514\n",
      "epoch515\n",
      "epoch516\n",
      "epoch517\n",
      "epoch518\n",
      "epoch519\n",
      "epoch520\n",
      "[Epoch 520/1500] [Batch 3448/3449][PSNR: 31.883287] [SSIM: 0.793441] [loss: -31.124725] ,[lab: 26.190471],[lch: 0.358865], [pixel: 0.000066],[VGG_loss: 18.440154]epoch521\n",
      "epoch522\n",
      "epoch523\n",
      "epoch524\n",
      "epoch525\n",
      "epoch526\n",
      "epoch527\n",
      "epoch528\n",
      "epoch529\n",
      "epoch530\n",
      "[Epoch 530/1500] [Batch 3448/3449][PSNR: 26.396092] [SSIM: 0.976545] [loss: -46.996426] ,[lab: 42.492910],[lch: 0.673808], [pixel: 0.000229],[VGG_loss: 1.426888]epoch531\n",
      "epoch532\n",
      "epoch533\n",
      "epoch534\n",
      "epoch535\n",
      "epoch536\n",
      "epoch537\n",
      "epoch538\n",
      "epoch539\n",
      "epoch540\n",
      "[Epoch 540/1500] [Batch 3448/3449][PSNR: 29.268910] [SSIM: 0.899619] [loss: -15.075632] ,[lab: 63.803586],[lch: 0.510020], [pixel: 0.000119],[VGG_loss: 5.982316]epoch541\n",
      "epoch542\n",
      "epoch543\n",
      "epoch544\n",
      "epoch545\n",
      "epoch546\n",
      "epoch547\n",
      "epoch548\n",
      "epoch549\n",
      "epoch550\n",
      "[Epoch 550/1500] [Batch 3448/3449][PSNR: 26.695588] [SSIM: 0.807846] [loss: 32.044884] ,[lab: 94.785594],[lch: 0.580975], [pixel: 0.000214],[VGG_loss: 12.233937]epoch551\n",
      "epoch552\n",
      "epoch553\n",
      "epoch554\n",
      "epoch555\n",
      "epoch556\n",
      "epoch557\n",
      "epoch558\n",
      "epoch559\n",
      "epoch560\n",
      "[Epoch 560/1500] [Batch 3448/3449][PSNR: 30.169212] [SSIM: 0.961511] [loss: -54.923149] ,[lab: 35.290410],[lch: 0.428582], [pixel: 0.000097],[VGG_loss: 1.651631]epoch561\n",
      "epoch562\n",
      "epoch563\n",
      "epoch564\n",
      "epoch565\n",
      "epoch566\n",
      "epoch567\n",
      "epoch568\n",
      "epoch569\n",
      "epoch570\n",
      "[Epoch 570/1500] [Batch 3448/3449][PSNR: 31.144848] [SSIM: 0.905200] [loss: 9.577471] ,[lab: 87.734766],[lch: 0.513068], [pixel: 0.000077],[VGG_loss: 7.231998]epoch571\n",
      "epoch572\n",
      "epoch573\n",
      "epoch574\n",
      "epoch575\n",
      "epoch576\n",
      "epoch577\n",
      "epoch578\n",
      "epoch579\n",
      "epoch580\n",
      "[Epoch 580/1500] [Batch 3448/3449][PSNR: 26.629258] [SSIM: 0.793565] [loss: 15.598601] ,[lab: 69.413328],[lch: 0.533297], [pixel: 0.000217],[VGG_loss: 20.208561]epoch581\n",
      "epoch582\n",
      "epoch583\n",
      "epoch584\n",
      "epoch585\n",
      "epoch586\n",
      "epoch587\n",
      "epoch588\n",
      "epoch589\n",
      "epoch590\n",
      "[Epoch 590/1500] [Batch 3448/3449][PSNR: 34.414183] [SSIM: 0.965475] [loss: -58.172523] ,[lab: 34.141109],[lch: 0.329877], [pixel: 0.000037],[VGG_loss: 0.935032]epoch591\n",
      "epoch592\n",
      "epoch593\n",
      "epoch594\n",
      "epoch595\n",
      "epoch596\n",
      "epoch597\n",
      "epoch598\n",
      "epoch599\n",
      "epoch600\n",
      "[Epoch 600/1500] [Batch 3448/3449][PSNR: 30.510270] [SSIM: 0.899062] [loss: -10.880327] ,[lab: 65.860203],[lch: 0.421039], [pixel: 0.000089],[VGG_loss: 8.955177]epoch601\n",
      "epoch602\n",
      "epoch603\n",
      "epoch604\n",
      "epoch605\n",
      "epoch606\n",
      "epoch607\n",
      "epoch608\n",
      "epoch609\n",
      "epoch610\n",
      "[Epoch 610/1500] [Batch 3448/3449][PSNR: 29.382749] [SSIM: 0.917872] [loss: -86.283440] ,[lab: 0.413100],[lch: 0.443779], [pixel: 0.000116],[VGG_loss: 0.652747]epoch611\n",
      "epoch612\n",
      "epoch613\n",
      "epoch614\n",
      "epoch615\n",
      "epoch616\n",
      "epoch617\n",
      "epoch618\n",
      "epoch619\n",
      "epoch620\n",
      "[Epoch 620/1500] [Batch 3448/3449][PSNR: 29.416463] [SSIM: 0.898857] [loss: 6.722685] ,[lab: 81.149195],[lch: 0.441963], [pixel: 0.000115],[VGG_loss: 11.039466]epoch621\n",
      "epoch622\n",
      "epoch623\n",
      "epoch624\n",
      "epoch625\n",
      "epoch626\n",
      "epoch627\n",
      "epoch628\n",
      "epoch629\n",
      "epoch630\n",
      "[Epoch 630/1500] [Batch 3448/3449][PSNR: 32.846811] [SSIM: 0.978954] [loss: -65.278717] ,[lab: 27.686986],[lch: 0.404465], [pixel: 0.000052],[VGG_loss: 0.884975]epoch631\n",
      "epoch632\n",
      "epoch633\n",
      "epoch634\n",
      "epoch635\n",
      "epoch636\n",
      "epoch637\n",
      "epoch638\n",
      "epoch639\n",
      "epoch640\n",
      "[Epoch 640/1500] [Batch 3448/3449][PSNR: 30.186998] [SSIM: 0.934765] [loss: -9.811793] ,[lab: 69.989641],[lch: 0.476647], [pixel: 0.000096],[VGG_loss: 8.908445]epoch641\n",
      "epoch642\n",
      "epoch643\n",
      "epoch644\n",
      "epoch645\n",
      "epoch646\n",
      "epoch647\n",
      "epoch648\n",
      "epoch649\n",
      "epoch650\n",
      "[Epoch 650/1500] [Batch 3448/3449][PSNR: 29.995999] [SSIM: 0.909114] [loss: -46.946346] ,[lab: 31.985582],[lch: 0.436059], [pixel: 0.000100],[VGG_loss: 7.618789]epoch651\n",
      "epoch652\n",
      "epoch653\n",
      "epoch654\n",
      "epoch655\n",
      "epoch656\n",
      "epoch657\n",
      "epoch658\n",
      "epoch659\n",
      "epoch660\n",
      "[Epoch 660/1500] [Batch 3448/3449][PSNR: 30.879377] [SSIM: 0.905954] [loss: -4.477952] ,[lab: 71.288219],[lch: 0.418059], [pixel: 0.000082],[VGG_loss: 10.648560]epoch661\n",
      "epoch662\n",
      "epoch663\n",
      "epoch664\n",
      "epoch665\n",
      "epoch666\n",
      "epoch667\n",
      "epoch668\n",
      "epoch669\n",
      "epoch670\n",
      "[Epoch 670/1500] [Batch 3448/3449][PSNR: 29.347529] [SSIM: 0.879168] [loss: -33.057041] ,[lab: 44.171973],[lch: 0.553678], [pixel: 0.000116],[VGG_loss: 5.150913]epoch671\n",
      "epoch672\n",
      "epoch673\n",
      "epoch674\n",
      "epoch675\n",
      "epoch676\n",
      "epoch677\n",
      "epoch678\n",
      "epoch679\n",
      "epoch680\n",
      "[Epoch 680/1500] [Batch 3448/3449][PSNR: 26.910430] [SSIM: 0.954275] [loss: -58.885483] ,[lab: 28.001758],[lch: 0.546853], [pixel: 0.000204],[VGG_loss: 3.071539]epoch681\n",
      "epoch682\n",
      "epoch683\n",
      "epoch684\n",
      "epoch685\n",
      "epoch686\n",
      "epoch687\n",
      "epoch688\n",
      "epoch689\n",
      "epoch690\n",
      "[Epoch 690/1500] [Batch 3448/3449][PSNR: 21.092786] [SSIM: 0.874455] [loss: -9.074333] ,[lab: 59.494859],[lch: 1.076112], [pixel: 0.000778],[VGG_loss: 8.114402]epoch691\n",
      "epoch692\n",
      "epoch693\n",
      "epoch694\n",
      "epoch695\n",
      "epoch696\n",
      "epoch697\n",
      "epoch698\n",
      "epoch699\n",
      "epoch700\n",
      "[Epoch 700/1500] [Batch 3448/3449][PSNR: 28.546648] [SSIM: 0.917967] [loss: -18.481579] ,[lab: 61.421355],[lch: 0.548998], [pixel: 0.000140],[VGG_loss: 6.403668]epoch701\n",
      "epoch702\n",
      "epoch703\n",
      "epoch704\n",
      "epoch705\n",
      "epoch706\n",
      "epoch707\n",
      "epoch708\n",
      "epoch709\n",
      "epoch710\n",
      "[Epoch 710/1500] [Batch 3448/3449][PSNR: 25.774681] [SSIM: 0.978800] [loss: -31.146906] ,[lab: 58.658000],[lch: 0.712819], [pixel: 0.000265],[VGG_loss: 0.946630]epoch711\n",
      "epoch712\n",
      "epoch713\n",
      "epoch714\n",
      "epoch715\n",
      "epoch716\n",
      "epoch717\n",
      "epoch718\n",
      "epoch719\n",
      "epoch720\n",
      "[Epoch 720/1500] [Batch 3448/3449][PSNR: 27.543149] [SSIM: 0.912308] [loss: -58.409985] ,[lab: 19.072541],[lch: 0.593307], [pixel: 0.000176],[VGG_loss: 7.815004]epoch721\n",
      "epoch722\n",
      "epoch723\n",
      "epoch724\n",
      "epoch725\n",
      "epoch726\n",
      "epoch727\n",
      "epoch728\n",
      "epoch729\n",
      "epoch730\n",
      "[Epoch 730/1500] [Batch 3448/3449][PSNR: 25.635334] [SSIM: 0.973256] [loss: -66.557709] ,[lab: 21.126980],[lch: 0.693863], [pixel: 0.000274],[VGG_loss: 2.702045]epoch731\n",
      "epoch732\n",
      "epoch733\n",
      "epoch734\n",
      "epoch735\n",
      "epoch736\n",
      "epoch737\n",
      "epoch738\n",
      "epoch739\n",
      "epoch740\n",
      "[Epoch 740/1500] [Batch 3448/3449][PSNR: 28.332436] [SSIM: 0.891768] [loss: -8.382811] ,[lab: 58.434828],[lch: 0.549101], [pixel: 0.000148],[VGG_loss: 16.867986]epoch741\n",
      "epoch742\n",
      "epoch743\n",
      "epoch744\n",
      "epoch745\n",
      "epoch746\n",
      "epoch747\n",
      "epoch748\n",
      "epoch749\n",
      "epoch750\n"
     ]
    }
   ],
   "source": [
    "# 设置训练日志：准备保存训练过程中的 PSNR 和 SSIM 结果到 CSV 文件\n",
    "# Training\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "import random\n",
    "\n",
    "f1 = open('psnr.csv','w',encoding='utf-8')#要改\n",
    "csv_writer1 = csv.writer(f1)\n",
    "f2 = open('SSIM.csv','w',encoding='utf-8')#要改\n",
    "csv_writer2 = csv.writer(f2)\n",
    "\n",
    "checkpoint_interval=10  # 每 10 个 epoch 保存一次模型\n",
    "epochs=start_epoch # 从上一次训练结束的 epoch 开始（可恢复训练）\n",
    "n_epochs=1500  # 总训练轮数  ##################################################################################\n",
    "sample_interval=1000  # 每训练 1000 个 batch 保存一次示例图片和指标\n",
    "\n",
    "# ingnored when opt.mode=='S'\n",
    "psnr_list = []   # 可用于保存每个 batch 的 PSNR（这里暂未使用）\n",
    "\n",
    "for epoch in range(epochs,n_epochs):\n",
    "    print(\"epoch\"+str(epoch))\n",
    "    for i, batch in enumerate(loader):\n",
    "\n",
    "        # Model inputs\n",
    "        real_A = Variable(batch[0]).cuda() #############################################\n",
    "        real_B = Variable(batch[1]).cuda() #############################################\n",
    "        real_A1=split(real_A)\n",
    "        real_B1=split(real_B)\n",
    "        # print(real_B1[3].shape) #############################################\n",
    "\n",
    "        # ------------------\n",
    "        #  Train Generators\n",
    "        # ------------------\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # GAN loss\n",
    "        fake_B = LightUNet(real_A)\n",
    "        # print(fake_B.shape) #############################################\n",
    "        \n",
    "        # Pixel-wise loss\n",
    "        loss_pixel =  criterion_pixelwise(fake_B, real_B1[3])\n",
    "        loss_ssim= -SSIM(fake_B, real_B1[3])\n",
    "        ssim_value = - loss_ssim.item()\n",
    "        loss_con = L_vgg(fake_B, real_B1[3])\n",
    "        loss_lab = L_lab(fake_B, real_B1[3])\n",
    "        loss_lch = L_lch(fake_B, real_B1[3])   \n",
    "\n",
    "        # Total loss\n",
    "        loss =  lambda_pixel * loss_pixel+  lambda_ssim*loss_ssim+\\\n",
    "            lambda_con*loss_con+  lambda_lab*loss_lab+  lambda_lch*loss_lch\n",
    "\n",
    "        loss.backward(retain_graph=True)\n",
    "        \n",
    "        # torch.nn.utils.clip_grad_norm_(LightUNet.parameters(), max_norm=1.0)  ##################### 梯度裁剪\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        # --------------\n",
    "        #  Log Progress\n",
    "        # --------------\n",
    "\n",
    "        # Determine approximate time left\n",
    "        batches_done = epoch * len(loader) + i\n",
    "        out_train= torch.clamp(fake_B, 0., 1.) \n",
    "        psnr_train = batch_PSNR(out_train,real_B, 1.)\n",
    "\n",
    "        # If at sample interval save image\n",
    "        if batches_done % sample_interval == 0:\n",
    "            sample_images(batches_done)\n",
    "            csv_writer1.writerow([str(psnr_train)])\n",
    "            csv_writer2.writerow([str(ssim_value)])\n",
    "            \n",
    "    if checkpoint_interval != -1 and epoch % checkpoint_interval == 0:\n",
    "        # Save model checkpoints  \n",
    "        torch.save(LightUNet.state_dict(), \"LightUNet_%d.pth\" % (epoch))\n",
    "        # Print log\n",
    "        sys.stdout.write(\n",
    "            \"\\r[Epoch %d/%d] [Batch %d/%d][PSNR: %f] [SSIM: %f] [loss: %f] ,[lab: %f],[lch: %f], [pixel: %f],[VGG_loss: %f]\"\n",
    "            % (\n",
    "                epoch,\n",
    "                n_epochs,\n",
    "                i,\n",
    "                len(loader),\n",
    "                psnr_train,\n",
    "                ssim_value,\n",
    "                loss.item(),\n",
    "                0.001*loss_lab.item(),\n",
    "                0.1*loss_lch.item(),\n",
    "                0.1*loss_pixel.item(),\n",
    "                100*loss_con.item(),\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# 测试模型参数量及算力需求\n",
    "#####################################################################################\n",
    "import torch\n",
    "from thop import profile\n",
    "\n",
    "# 模型定义\n",
    "model = LU2Net.LU2Net().cuda()\n",
    "\n",
    "# 统计参数量\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Params: {num_params / 1e6:.2f}M\")\n",
    "\n",
    "# 假设输入是 3x256x256 图像，根据你的任务改成实际输入大小\n",
    "dummy_input = torch.randn(1, 3, 256, 256).to(next(model.parameters()).device)\n",
    "\n",
    "# 统计 FLOPs 和 Params\n",
    "flops, params = profile(model, inputs=(dummy_input,))\n",
    "print(f\"FLOPs: {flops / 1e9:.2f}G\")\n",
    "print(f\"Params (from thop): {params / 1e6:.2f}M\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
